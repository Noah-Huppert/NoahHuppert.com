{
    "version": 3,
    "terraform_version": "0.10.8",
    "serial": 5,
    "lineage": "0359e738-a0d0-4163-98a2-1d4d8e272989",
    "modules": [
        {
            "path": [
                "root"
            ],
            "outputs": {},
            "resources": {
                "data.template_file.master_yaml": {
                    "type": "template_file",
                    "depends_on": [
                        "digitalocean_droplet.k8s_etcd"
                    ],
                    "primary": {
                        "id": "5cccfe36e12cc41cd7859e35f5a8fede797c727409b6d07a3dc3490d2fd94254",
                        "attributes": {
                            "id": "5cccfe36e12cc41cd7859e35f5a8fede797c727409b6d07a3dc3490d2fd94254",
                            "rendered": "#cloud-config\n\nwrite_files:\n  - path: \"/etc/flannel/options.env\"\n    permissions: \"0755\"\n    content: |\n        FLANNELD_IFACE=$private_ipv4\n        FLANNELD_ETCD_ENDPOINTS=https://10.132.44.189:2379\n        FLANNELD_ETCD_CAFILE=/etc/ssl/etcd/ca.pem\n        FLANNELD_ETCD_CERTFILE=/etc/ssl/etcd/client.pem\n        FLANNELD_ETCD_KEYFILE=/etc/ssl/etcd/client-key.pem\n  - path: \"/etc/systemd/system/flanneld.service.d/40-ExecStartPre-symlink.conf\"\n    permissions: \"0755\"\n    content: |\n        [Service]\n        ExecStartPre=/usr/bin/ln -sf /etc/flannel/options.env /run/flannel/options.env\n  - path: \"/etc/systemd/system/docker.service.d/40-flannel.conf\"\n    permissions: \"0755\"\n    content: |\n        [Unit]\n        Requires=flanneld.service\n        After=flanneld.service\n  - path: \"/etc/systemd/system/kubelet.service\"\n    permissions: \"0755\"\n    content: |\n        [Service]\n        Environment=KUBELET_IMAGE_TAG=v1.7.3_coreos.0\n        Environment=\"RKT_RUN_ARGS=--uuid-file-save=/var/run/kubelet-pod.uuid \\\n          --volume var-log,kind=host,source=/var/log \\\n          --mount volume=var-log,target=/var/log \\\n          --volume dns,kind=host,source=/etc/resolv.conf \\\n          --mount volume=dns,target=/etc/resolv.conf\"\n        ExecStartPre=/usr/bin/mkdir -p /etc/kubernetes/manifests\n        ExecStartPre=/usr/bin/mkdir -p /var/log/containers\n        ExecStartPre=-/usr/bin/rkt rm --uuid-file=/var/run/kubelet-pod.uuid\n        ExecStart=/usr/lib/coreos/kubelet-wrapper \\\n          --anonymous-auth=false \\\n          --client-ca-file=/etc/kubernetes/ssl/ca.pem \\\n          --api-servers=http://127.0.0.1:8080 \\\n          --network-plugin-dir=/etc/kubernetes/cni/net.d \\\n          --container-runtime=docker \\\n          --allow-privileged=true \\\n          --pod-manifest-path=/etc/kubernetes/manifests \\\n          --hostname-override=$private_ipv4 \\\n          --cluster-dns=10.3.0.10 \\\n          --cluster-domain=cluster.local \\\n          --node-labels=kubernetes.io/role=master \\\n          --register-with-taints=node-role.kubernetes.io/master=:NoSchedule\n        ExecStop=-/usr/bin/rkt stop --uuid-file=/var/run/kubelet-pod.uuid\n        Restart=always\n        RestartSec=10\n\n        [Install]\n        WantedBy=multi-user.target\n  - path: \"/etc/kubernetes/manifests/kube-apiserver.yaml\"\n    permissions: \"0755\"\n    content: |\n        apiVersion: v1\n        kind: Pod\n        metadata:\n          name: kube-apiserver\n          namespace: kube-system\n        spec:\n          hostNetwork: true\n          containers:\n          - name: kube-apiserver\n            image: quay.io/coreos/hyperkube:v1.7.3_coreos.0\n            command:\n            - /hyperkube\n            - apiserver\n            - --bind-address=0.0.0.0\n            - --etcd-servers=https://10.132.44.189:2379\n            - --etcd-cafile=/etc/kubernetes/ssl/ca.pem\n            - --etcd-certfile=/etc/kubernetes/ssl/client.pem\n            - --etcd-keyfile=/etc/kubernetes/ssl/client-key.pem\n            - --kubelet-client-certificate=/etc/kubernetes/ssl/client.pem\n            - --kubelet-client-key=/etc/kubernetes/ssl/client-key.pem\n            - --allow-privileged=true\n            - --service-cluster-ip-range=10.3.0.0/24\n            - --secure-port=443\n            - --storage-backend=etcd2\n            - --advertise-address=$private_ipv4\n            - --admission-control=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,ResourceQuota\n            - --tls-cert-file=/etc/kubernetes/ssl/apiserver.pem\n            - --tls-private-key-file=/etc/kubernetes/ssl/apiserver-key.pem\n            - --client-ca-file=/etc/kubernetes/ssl/ca.pem\n            - --service-account-key-file=/etc/kubernetes/ssl/apiserver-key.pem\n            - --anonymous-auth=false\n            livenessProbe:\n              httpGet:\n                host: 127.0.0.1\n                port: 8080\n                path: /healthz\n              initialDelaySeconds: 15\n              timeoutSeconds: 15\n            ports:\n            - containerPort: 443\n              hostPort: 443\n              name: https\n            - containerPort: 8080\n              hostPort: 8080\n              name: local\n            volumeMounts:\n            - mountPath: /etc/kubernetes/ssl\n              name: ssl-certs-kubernetes\n              readOnly: true\n            - mountPath: /etc/ssl/certs\n              name: ssl-certs-host\n              readOnly: true\n          volumes:\n          - hostPath:\n              path: /etc/kubernetes/ssl\n            name: ssl-certs-kubernetes\n          - hostPath:\n              path: /usr/share/ca-certificates\n            name: ssl-certs-host\n  - path: \"/etc/kubernetes/manifests/kube-proxy.yaml\"\n    permissions: \"0755\"\n    content: |\n        apiVersion: v1\n        kind: Pod\n        metadata:\n          name: kube-proxy\n          namespace: kube-system\n        spec:\n          hostNetwork: true\n          containers:\n          - name: kube-proxy\n            image: quay.io/coreos/hyperkube:v1.7.3_coreos.0\n            command:\n            - /hyperkube\n            - proxy\n            - --master=http://127.0.0.1:8080\n            - --proxy-mode=iptables\n            securityContext:\n              privileged: true\n            volumeMounts:\n            - mountPath: /etc/ssl/certs\n              name: ssl-certs-host\n              readOnly: true\n          volumes:\n          - hostPath:\n              path: /usr/share/ca-certificates\n            name: ssl-certs-host\n  - path: \"/etc/kubernetes/manifests/kube-controller-manager.yaml\"\n    permissions: \"0755\"\n    content: |\n        apiVersion: v1\n        kind: Pod\n        metadata:\n          name: kube-controller-manager\n          namespace: kube-system\n        spec:\n          hostNetwork: true\n          containers:\n          - name: kube-controller-manager\n            image: quay.io/coreos/hyperkube:v1.7.3_coreos.0\n            command:\n            - /hyperkube\n            - controller-manager\n            - --master=http://127.0.0.1:8080\n            - --leader-elect=true\n            - --service-account-private-key-file=/etc/kubernetes/ssl/apiserver-key.pem\n            - --root-ca-file=/etc/kubernetes/ssl/ca.pem\n            livenessProbe:\n              httpGet:\n                host: 127.0.0.1\n                path: /healthz\n                port: 10252\n              initialDelaySeconds: 15\n              timeoutSeconds: 1\n            volumeMounts:\n            - mountPath: /etc/kubernetes/ssl\n              name: ssl-certs-kubernetes\n              readOnly: true\n            - mountPath: /etc/ssl/certs\n              name: ssl-certs-host\n              readOnly: true\n          volumes:\n          - hostPath:\n              path: /etc/kubernetes/ssl\n            name: ssl-certs-kubernetes\n          - hostPath:\n              path: /usr/share/ca-certificates\n            name: ssl-certs-host\n  - path: \"/etc/kubernetes/manifests/kube-scheduler.yaml\"\n    permissions: \"0755\"\n    content: |\n        apiVersion: v1\n        kind: Pod\n        metadata:\n          name: kube-scheduler\n          namespace: kube-system\n        spec:\n          hostNetwork: true\n          containers:\n          - name: kube-scheduler\n            image: quay.io/coreos/hyperkube:v1.7.3_coreos.0\n            command:\n            - /hyperkube\n            - scheduler\n            - --master=http://127.0.0.1:8080\n            - --leader-elect=true\n            livenessProbe:\n              httpGet:\n                host: 127.0.0.1\n                path: /healthz\n                port: 10251\n              initialDelaySeconds: 15\n              timeoutSeconds: 15\n",
                            "template": "#cloud-config\n\nwrite_files:\n  - path: \"/etc/flannel/options.env\"\n    permissions: \"0755\"\n    content: |\n        FLANNELD_IFACE=$private_ipv4\n        FLANNELD_ETCD_ENDPOINTS=https://${ETCD_IP}:2379\n        FLANNELD_ETCD_CAFILE=/etc/ssl/etcd/ca.pem\n        FLANNELD_ETCD_CERTFILE=/etc/ssl/etcd/client.pem\n        FLANNELD_ETCD_KEYFILE=/etc/ssl/etcd/client-key.pem\n  - path: \"/etc/systemd/system/flanneld.service.d/40-ExecStartPre-symlink.conf\"\n    permissions: \"0755\"\n    content: |\n        [Service]\n        ExecStartPre=/usr/bin/ln -sf /etc/flannel/options.env /run/flannel/options.env\n  - path: \"/etc/systemd/system/docker.service.d/40-flannel.conf\"\n    permissions: \"0755\"\n    content: |\n        [Unit]\n        Requires=flanneld.service\n        After=flanneld.service\n  - path: \"/etc/systemd/system/kubelet.service\"\n    permissions: \"0755\"\n    content: |\n        [Service]\n        Environment=KUBELET_IMAGE_TAG=${HYPERKUBE_VERSION}\n        Environment=\"RKT_RUN_ARGS=--uuid-file-save=/var/run/kubelet-pod.uuid \\\n          --volume var-log,kind=host,source=/var/log \\\n          --mount volume=var-log,target=/var/log \\\n          --volume dns,kind=host,source=/etc/resolv.conf \\\n          --mount volume=dns,target=/etc/resolv.conf\"\n        ExecStartPre=/usr/bin/mkdir -p /etc/kubernetes/manifests\n        ExecStartPre=/usr/bin/mkdir -p /var/log/containers\n        ExecStartPre=-/usr/bin/rkt rm --uuid-file=/var/run/kubelet-pod.uuid\n        ExecStart=/usr/lib/coreos/kubelet-wrapper \\\n          --anonymous-auth=false \\\n          --client-ca-file=/etc/kubernetes/ssl/ca.pem \\\n          --api-servers=http://127.0.0.1:8080 \\\n          --network-plugin-dir=/etc/kubernetes/cni/net.d \\\n          --container-runtime=docker \\\n          --allow-privileged=true \\\n          --pod-manifest-path=/etc/kubernetes/manifests \\\n          --hostname-override=$private_ipv4 \\\n          --cluster-dns=${DNS_SERVICE_IP} \\\n          --cluster-domain=cluster.local \\\n          --node-labels=kubernetes.io/role=master \\\n          --register-with-taints=node-role.kubernetes.io/master=:NoSchedule\n        ExecStop=-/usr/bin/rkt stop --uuid-file=/var/run/kubelet-pod.uuid\n        Restart=always\n        RestartSec=10\n\n        [Install]\n        WantedBy=multi-user.target\n  - path: \"/etc/kubernetes/manifests/kube-apiserver.yaml\"\n    permissions: \"0755\"\n    content: |\n        apiVersion: v1\n        kind: Pod\n        metadata:\n          name: kube-apiserver\n          namespace: kube-system\n        spec:\n          hostNetwork: true\n          containers:\n          - name: kube-apiserver\n            image: quay.io/coreos/hyperkube:${HYPERKUBE_VERSION}\n            command:\n            - /hyperkube\n            - apiserver\n            - --bind-address=0.0.0.0\n            - --etcd-servers=https://${ETCD_IP}:2379\n            - --etcd-cafile=/etc/kubernetes/ssl/ca.pem\n            - --etcd-certfile=/etc/kubernetes/ssl/client.pem\n            - --etcd-keyfile=/etc/kubernetes/ssl/client-key.pem\n            - --kubelet-client-certificate=/etc/kubernetes/ssl/client.pem\n            - --kubelet-client-key=/etc/kubernetes/ssl/client-key.pem\n            - --allow-privileged=true\n            - --service-cluster-ip-range=${SERVICE_IP_RANGE}\n            - --secure-port=443\n            - --storage-backend=etcd2\n            - --advertise-address=$private_ipv4\n            - --admission-control=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,ResourceQuota\n            - --tls-cert-file=/etc/kubernetes/ssl/apiserver.pem\n            - --tls-private-key-file=/etc/kubernetes/ssl/apiserver-key.pem\n            - --client-ca-file=/etc/kubernetes/ssl/ca.pem\n            - --service-account-key-file=/etc/kubernetes/ssl/apiserver-key.pem\n            - --anonymous-auth=false\n            livenessProbe:\n              httpGet:\n                host: 127.0.0.1\n                port: 8080\n                path: /healthz\n              initialDelaySeconds: 15\n              timeoutSeconds: 15\n            ports:\n            - containerPort: 443\n              hostPort: 443\n              name: https\n            - containerPort: 8080\n              hostPort: 8080\n              name: local\n            volumeMounts:\n            - mountPath: /etc/kubernetes/ssl\n              name: ssl-certs-kubernetes\n              readOnly: true\n            - mountPath: /etc/ssl/certs\n              name: ssl-certs-host\n              readOnly: true\n          volumes:\n          - hostPath:\n              path: /etc/kubernetes/ssl\n            name: ssl-certs-kubernetes\n          - hostPath:\n              path: /usr/share/ca-certificates\n            name: ssl-certs-host\n  - path: \"/etc/kubernetes/manifests/kube-proxy.yaml\"\n    permissions: \"0755\"\n    content: |\n        apiVersion: v1\n        kind: Pod\n        metadata:\n          name: kube-proxy\n          namespace: kube-system\n        spec:\n          hostNetwork: true\n          containers:\n          - name: kube-proxy\n            image: quay.io/coreos/hyperkube:${HYPERKUBE_VERSION}\n            command:\n            - /hyperkube\n            - proxy\n            - --master=http://127.0.0.1:8080\n            - --proxy-mode=iptables\n            securityContext:\n              privileged: true\n            volumeMounts:\n            - mountPath: /etc/ssl/certs\n              name: ssl-certs-host\n              readOnly: true\n          volumes:\n          - hostPath:\n              path: /usr/share/ca-certificates\n            name: ssl-certs-host\n  - path: \"/etc/kubernetes/manifests/kube-controller-manager.yaml\"\n    permissions: \"0755\"\n    content: |\n        apiVersion: v1\n        kind: Pod\n        metadata:\n          name: kube-controller-manager\n          namespace: kube-system\n        spec:\n          hostNetwork: true\n          containers:\n          - name: kube-controller-manager\n            image: quay.io/coreos/hyperkube:${HYPERKUBE_VERSION}\n            command:\n            - /hyperkube\n            - controller-manager\n            - --master=http://127.0.0.1:8080\n            - --leader-elect=true\n            - --service-account-private-key-file=/etc/kubernetes/ssl/apiserver-key.pem\n            - --root-ca-file=/etc/kubernetes/ssl/ca.pem\n            livenessProbe:\n              httpGet:\n                host: 127.0.0.1\n                path: /healthz\n                port: 10252\n              initialDelaySeconds: 15\n              timeoutSeconds: 1\n            volumeMounts:\n            - mountPath: /etc/kubernetes/ssl\n              name: ssl-certs-kubernetes\n              readOnly: true\n            - mountPath: /etc/ssl/certs\n              name: ssl-certs-host\n              readOnly: true\n          volumes:\n          - hostPath:\n              path: /etc/kubernetes/ssl\n            name: ssl-certs-kubernetes\n          - hostPath:\n              path: /usr/share/ca-certificates\n            name: ssl-certs-host\n  - path: \"/etc/kubernetes/manifests/kube-scheduler.yaml\"\n    permissions: \"0755\"\n    content: |\n        apiVersion: v1\n        kind: Pod\n        metadata:\n          name: kube-scheduler\n          namespace: kube-system\n        spec:\n          hostNetwork: true\n          containers:\n          - name: kube-scheduler\n            image: quay.io/coreos/hyperkube:${HYPERKUBE_VERSION}\n            command:\n            - /hyperkube\n            - scheduler\n            - --master=http://127.0.0.1:8080\n            - --leader-elect=true\n            livenessProbe:\n              httpGet:\n                host: 127.0.0.1\n                path: /healthz\n                port: 10251\n              initialDelaySeconds: 15\n              timeoutSeconds: 15\n",
                            "vars.%": "5",
                            "vars.DNS_SERVICE_IP": "10.3.0.10",
                            "vars.ETCD_IP": "10.132.44.189",
                            "vars.HYPERKUBE_VERSION": "v1.7.3_coreos.0",
                            "vars.POD_NETWORK": "10.2.0.0/16",
                            "vars.SERVICE_IP_RANGE": "10.3.0.0/24"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": ""
                },
                "data.template_file.worker_yaml": {
                    "type": "template_file",
                    "depends_on": [
                        "digitalocean_droplet.k8s_etcd",
                        "digitalocean_droplet.k8s_master"
                    ],
                    "primary": {
                        "id": "0e1321d834f2fb04bf0b64a496f3e5fc2579e1d1edd8629733eca0701abbfe61",
                        "attributes": {
                            "id": "0e1321d834f2fb04bf0b64a496f3e5fc2579e1d1edd8629733eca0701abbfe61",
                            "rendered": "#cloud-config\n\n\nwrite_files:\n  - path: \"/etc/flannel/options.env\"\n    permissions: \"0755\"\n    content: |\n        FLANNELD_IFACE=$private_ipv4\n        FLANNELD_ETCD_ENDPOINTS=https://10.132.44.189:2379\n        FLANNELD_ETCD_CAFILE=/etc/ssl/etcd/ca.pem\n        FLANNELD_ETCD_CERTFILE=/etc/ssl/etcd/worker.pem\n        FLANNELD_ETCD_KEYFILE=/etc/ssl/etcd/worker-key.pem\n  - path: \"/etc/systemd/system/flanneld.service.d/40-ExecStartPre-symlink.conf\"\n    permissions: \"0755\"\n    content: |\n        [Service]\n        ExecStartPre=/usr/bin/ln -sf /etc/flannel/options.env /run/flannel/options.env\n  - path: \"/etc/systemd/system/docker.service.d/40-flannel.conf\"\n    permissions: \"0755\"\n    content: |\n        [Unit]\n        Requires=flanneld.service\n        After=flanneld.service\n  - path: \"/etc/systemd/system/kubelet.service\"\n    permissions: \"0755\"\n    content: |\n        [Service]\n        Environment=KUBELET_IMAGE_TAG=v1.7.3_coreos.0\n        Environment=\"RKT_RUN_ARGS=--uuid-file-save=/var/run/kubelet-pod.uuid \\\n          --volume dns,kind=host,source=/etc/resolv.conf \\\n          --mount volume=dns,target=/etc/resolv.conf \\\n          --volume var-log,kind=host,source=/var/log \\\n          --mount volume=var-log,target=/var/log\"\n        ExecStartPre=/usr/bin/mkdir -p /etc/kubernetes/manifests\n        ExecStartPre=/usr/bin/mkdir -p /var/log/containers\n        ExecStartPre=-/usr/bin/rkt rm --uuid-file=/var/run/kubelet-pod.uuid\n        ExecStart=/usr/lib/coreos/kubelet-wrapper \\\n          --anonymous-auth=false \\\n          --client-ca-file=/etc/kubernetes/ssl/ca.pem \\\n          --api-servers=https://10.132.69.8 \\\n          --network-plugin-dir=/etc/kubernetes/cni/net.d \\\n          --container-runtime=docker \\\n          --register-node=true \\\n          --allow-privileged=true \\\n          --pod-manifest-path=/etc/kubernetes/manifests \\\n          --hostname-override=$private_ipv4 \\\n          --cluster-dns=10.3.0.10 \\\n          --cluster-domain=cluster.local \\\n          --kubeconfig=/etc/kubernetes/worker-kubeconfig.yaml \\\n          --tls-cert-file=/etc/kubernetes/ssl/worker.pem \\\n          --tls-private-key-file=/etc/kubernetes/ssl/worker-key.pem \\\n          --node-labels=kubernetes.io/role=node\n        ExecStop=-/usr/bin/rkt stop --uuid-file=/var/run/kubelet-pod.uuid\n        Restart=always\n        RestartSec=10\n\n        [Install]\n        WantedBy=multi-user.target\n  - path: \"/etc/kubernetes/manifests/kube-proxy.yaml\"\n    permissions: \"0755\"\n    content: |\n        apiVersion: v1\n        kind: Pod\n        metadata:\n          name: kube-proxy\n          namespace: kube-system\n        spec:\n          hostNetwork: true\n          containers:\n          - name: kube-proxy\n            image: quay.io/coreos/hyperkube:v1.7.3_coreos.0\n            command:\n            - /hyperkube\n            - proxy\n            - --master=https://10.132.69.8\n            - --kubeconfig=/etc/kubernetes/worker-kubeconfig.yaml\n            - --proxy-mode=iptables\n            securityContext:\n              privileged: true\n            volumeMounts:\n              - mountPath: /etc/ssl/certs\n                name: \"ssl-certs\"\n              - mountPath: /etc/kubernetes/worker-kubeconfig.yaml\n                name: \"kubeconfig\"\n                readOnly: true\n              - mountPath: /etc/kubernetes/ssl\n                name: \"etc-kube-ssl\"\n                readOnly: true\n          volumes:\n            - name: \"ssl-certs\"\n              hostPath:\n                path: \"/usr/share/ca-certificates\"\n            - name: \"kubeconfig\"\n              hostPath:\n                path: \"/etc/kubernetes/worker-kubeconfig.yaml\"\n            - name: \"etc-kube-ssl\"\n              hostPath:\n                path: \"/etc/kubernetes/ssl\"\n  - path: \"/etc/kubernetes/worker-kubeconfig.yaml\"\n    permissions: \"0755\"\n    content: |\n        apiVersion: v1\n        kind: Config\n        clusters:\n        - name: local\n          cluster:\n            certificate-authority: /etc/kubernetes/ssl/ca.pem\n        users:\n        - name: kubelet\n          user:\n            client-certificate: /etc/kubernetes/ssl/worker.pem\n            client-key: /etc/kubernetes/ssl/worker-key.pem\n        contexts:\n        - context:\n            cluster: local\n            user: kubelet\n          name: kubelet-context\n        current-context: kubelet-context\n",
                            "template": "#cloud-config\n\n\nwrite_files:\n  - path: \"/etc/flannel/options.env\"\n    permissions: \"0755\"\n    content: |\n        FLANNELD_IFACE=$private_ipv4\n        FLANNELD_ETCD_ENDPOINTS=https://${ETCD_IP}:2379\n        FLANNELD_ETCD_CAFILE=/etc/ssl/etcd/ca.pem\n        FLANNELD_ETCD_CERTFILE=/etc/ssl/etcd/worker.pem\n        FLANNELD_ETCD_KEYFILE=/etc/ssl/etcd/worker-key.pem\n  - path: \"/etc/systemd/system/flanneld.service.d/40-ExecStartPre-symlink.conf\"\n    permissions: \"0755\"\n    content: |\n        [Service]\n        ExecStartPre=/usr/bin/ln -sf /etc/flannel/options.env /run/flannel/options.env\n  - path: \"/etc/systemd/system/docker.service.d/40-flannel.conf\"\n    permissions: \"0755\"\n    content: |\n        [Unit]\n        Requires=flanneld.service\n        After=flanneld.service\n  - path: \"/etc/systemd/system/kubelet.service\"\n    permissions: \"0755\"\n    content: |\n        [Service]\n        Environment=KUBELET_IMAGE_TAG=${HYPERKUBE_VERSION}\n        Environment=\"RKT_RUN_ARGS=--uuid-file-save=/var/run/kubelet-pod.uuid \\\n          --volume dns,kind=host,source=/etc/resolv.conf \\\n          --mount volume=dns,target=/etc/resolv.conf \\\n          --volume var-log,kind=host,source=/var/log \\\n          --mount volume=var-log,target=/var/log\"\n        ExecStartPre=/usr/bin/mkdir -p /etc/kubernetes/manifests\n        ExecStartPre=/usr/bin/mkdir -p /var/log/containers\n        ExecStartPre=-/usr/bin/rkt rm --uuid-file=/var/run/kubelet-pod.uuid\n        ExecStart=/usr/lib/coreos/kubelet-wrapper \\\n          --anonymous-auth=false \\\n          --client-ca-file=/etc/kubernetes/ssl/ca.pem \\\n          --api-servers=https://${MASTER_HOST} \\\n          --network-plugin-dir=/etc/kubernetes/cni/net.d \\\n          --container-runtime=docker \\\n          --register-node=true \\\n          --allow-privileged=true \\\n          --pod-manifest-path=/etc/kubernetes/manifests \\\n          --hostname-override=$private_ipv4 \\\n          --cluster-dns=${DNS_SERVICE_IP} \\\n          --cluster-domain=cluster.local \\\n          --kubeconfig=/etc/kubernetes/worker-kubeconfig.yaml \\\n          --tls-cert-file=/etc/kubernetes/ssl/worker.pem \\\n          --tls-private-key-file=/etc/kubernetes/ssl/worker-key.pem \\\n          --node-labels=kubernetes.io/role=node\n        ExecStop=-/usr/bin/rkt stop --uuid-file=/var/run/kubelet-pod.uuid\n        Restart=always\n        RestartSec=10\n\n        [Install]\n        WantedBy=multi-user.target\n  - path: \"/etc/kubernetes/manifests/kube-proxy.yaml\"\n    permissions: \"0755\"\n    content: |\n        apiVersion: v1\n        kind: Pod\n        metadata:\n          name: kube-proxy\n          namespace: kube-system\n        spec:\n          hostNetwork: true\n          containers:\n          - name: kube-proxy\n            image: quay.io/coreos/hyperkube:${HYPERKUBE_VERSION}\n            command:\n            - /hyperkube\n            - proxy\n            - --master=https://${MASTER_HOST}\n            - --kubeconfig=/etc/kubernetes/worker-kubeconfig.yaml\n            - --proxy-mode=iptables\n            securityContext:\n              privileged: true\n            volumeMounts:\n              - mountPath: /etc/ssl/certs\n                name: \"ssl-certs\"\n              - mountPath: /etc/kubernetes/worker-kubeconfig.yaml\n                name: \"kubeconfig\"\n                readOnly: true\n              - mountPath: /etc/kubernetes/ssl\n                name: \"etc-kube-ssl\"\n                readOnly: true\n          volumes:\n            - name: \"ssl-certs\"\n              hostPath:\n                path: \"/usr/share/ca-certificates\"\n            - name: \"kubeconfig\"\n              hostPath:\n                path: \"/etc/kubernetes/worker-kubeconfig.yaml\"\n            - name: \"etc-kube-ssl\"\n              hostPath:\n                path: \"/etc/kubernetes/ssl\"\n  - path: \"/etc/kubernetes/worker-kubeconfig.yaml\"\n    permissions: \"0755\"\n    content: |\n        apiVersion: v1\n        kind: Config\n        clusters:\n        - name: local\n          cluster:\n            certificate-authority: /etc/kubernetes/ssl/ca.pem\n        users:\n        - name: kubelet\n          user:\n            client-certificate: /etc/kubernetes/ssl/worker.pem\n            client-key: /etc/kubernetes/ssl/worker-key.pem\n        contexts:\n        - context:\n            cluster: local\n            user: kubelet\n          name: kubelet-context\n        current-context: kubelet-context\n",
                            "vars.%": "4",
                            "vars.DNS_SERVICE_IP": "10.3.0.10",
                            "vars.ETCD_IP": "10.132.44.189",
                            "vars.HYPERKUBE_VERSION": "v1.7.3_coreos.0",
                            "vars.MASTER_HOST": "10.132.69.8"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": ""
                },
                "digitalocean_droplet.k8s_etcd": {
                    "type": "digitalocean_droplet",
                    "depends_on": [],
                    "primary": {
                        "id": "68973384",
                        "attributes": {
                            "disk": "20",
                            "id": "68973384",
                            "image": "coreos-stable",
                            "ipv4_address": "104.236.122.177",
                            "ipv4_address_private": "10.132.44.189",
                            "locked": "false",
                            "name": "k8s-etcd",
                            "price_hourly": "0.00744",
                            "price_monthly": "5",
                            "private_networking": "true",
                            "region": "nyc3",
                            "resize_disk": "true",
                            "size": "512mb",
                            "ssh_keys.#": "1",
                            "ssh_keys.0": "b4:9a:a0:b0:e5:e1:39:5f:0b:5c:1e:10:6d:d9:77:5b",
                            "status": "active",
                            "tags.#": "0",
                            "user_data": "#cloud-config\n\ncoreos:\n  etcd2:\n    advertise-client-urls: https://$private_ipv4:2379 # multi-region and multi-cloud deployments need to use $public_ipv4\n    listen-client-urls: https://0.0.0.0:2379\n    client-cert-auth: true\n    trusted-ca-file: /etc/kubernetes/ssl/ca.pem\n    cert-file: /etc/kubernetes/ssl/etcd.pem\n    key-file: /etc/kubernetes/ssl/etcd-key.pem\n  units:\n    - name: etcd2.service\n      command: start\n\n",
                            "vcpus": "1"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": ""
                },
                "digitalocean_droplet.k8s_master": {
                    "type": "digitalocean_droplet",
                    "depends_on": [
                        "data.template_file.master_yaml",
                        "digitalocean_droplet.k8s_etcd"
                    ],
                    "primary": {
                        "id": "68973448",
                        "attributes": {
                            "disk": "30",
                            "id": "68973448",
                            "image": "coreos-stable",
                            "ipv4_address": "45.55.130.221",
                            "ipv4_address_private": "10.132.69.8",
                            "locked": "false",
                            "name": "k8s-master",
                            "price_hourly": "0.01488",
                            "price_monthly": "10",
                            "private_networking": "true",
                            "region": "nyc3",
                            "resize_disk": "true",
                            "size": "1gb",
                            "ssh_keys.#": "1",
                            "ssh_keys.0": "b4:9a:a0:b0:e5:e1:39:5f:0b:5c:1e:10:6d:d9:77:5b",
                            "status": "active",
                            "tags.#": "0",
                            "user_data": "#cloud-config\n\nwrite_files:\n  - path: \"/etc/flannel/options.env\"\n    permissions: \"0755\"\n    content: |\n        FLANNELD_IFACE=$private_ipv4\n        FLANNELD_ETCD_ENDPOINTS=https://10.132.44.189:2379\n        FLANNELD_ETCD_CAFILE=/etc/ssl/etcd/ca.pem\n        FLANNELD_ETCD_CERTFILE=/etc/ssl/etcd/client.pem\n        FLANNELD_ETCD_KEYFILE=/etc/ssl/etcd/client-key.pem\n  - path: \"/etc/systemd/system/flanneld.service.d/40-ExecStartPre-symlink.conf\"\n    permissions: \"0755\"\n    content: |\n        [Service]\n        ExecStartPre=/usr/bin/ln -sf /etc/flannel/options.env /run/flannel/options.env\n  - path: \"/etc/systemd/system/docker.service.d/40-flannel.conf\"\n    permissions: \"0755\"\n    content: |\n        [Unit]\n        Requires=flanneld.service\n        After=flanneld.service\n  - path: \"/etc/systemd/system/kubelet.service\"\n    permissions: \"0755\"\n    content: |\n        [Service]\n        Environment=KUBELET_IMAGE_TAG=v1.7.3_coreos.0\n        Environment=\"RKT_RUN_ARGS=--uuid-file-save=/var/run/kubelet-pod.uuid \\\n          --volume var-log,kind=host,source=/var/log \\\n          --mount volume=var-log,target=/var/log \\\n          --volume dns,kind=host,source=/etc/resolv.conf \\\n          --mount volume=dns,target=/etc/resolv.conf\"\n        ExecStartPre=/usr/bin/mkdir -p /etc/kubernetes/manifests\n        ExecStartPre=/usr/bin/mkdir -p /var/log/containers\n        ExecStartPre=-/usr/bin/rkt rm --uuid-file=/var/run/kubelet-pod.uuid\n        ExecStart=/usr/lib/coreos/kubelet-wrapper \\\n          --anonymous-auth=false \\\n          --client-ca-file=/etc/kubernetes/ssl/ca.pem \\\n          --api-servers=http://127.0.0.1:8080 \\\n          --network-plugin-dir=/etc/kubernetes/cni/net.d \\\n          --container-runtime=docker \\\n          --allow-privileged=true \\\n          --pod-manifest-path=/etc/kubernetes/manifests \\\n          --hostname-override=$private_ipv4 \\\n          --cluster-dns=10.3.0.10 \\\n          --cluster-domain=cluster.local \\\n          --node-labels=kubernetes.io/role=master \\\n          --register-with-taints=node-role.kubernetes.io/master=:NoSchedule\n        ExecStop=-/usr/bin/rkt stop --uuid-file=/var/run/kubelet-pod.uuid\n        Restart=always\n        RestartSec=10\n\n        [Install]\n        WantedBy=multi-user.target\n  - path: \"/etc/kubernetes/manifests/kube-apiserver.yaml\"\n    permissions: \"0755\"\n    content: |\n        apiVersion: v1\n        kind: Pod\n        metadata:\n          name: kube-apiserver\n          namespace: kube-system\n        spec:\n          hostNetwork: true\n          containers:\n          - name: kube-apiserver\n            image: quay.io/coreos/hyperkube:v1.7.3_coreos.0\n            command:\n            - /hyperkube\n            - apiserver\n            - --bind-address=0.0.0.0\n            - --etcd-servers=https://10.132.44.189:2379\n            - --etcd-cafile=/etc/kubernetes/ssl/ca.pem\n            - --etcd-certfile=/etc/kubernetes/ssl/client.pem\n            - --etcd-keyfile=/etc/kubernetes/ssl/client-key.pem\n            - --kubelet-client-certificate=/etc/kubernetes/ssl/client.pem\n            - --kubelet-client-key=/etc/kubernetes/ssl/client-key.pem\n            - --allow-privileged=true\n            - --service-cluster-ip-range=10.3.0.0/24\n            - --secure-port=443\n            - --storage-backend=etcd2\n            - --advertise-address=$private_ipv4\n            - --admission-control=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,ResourceQuota\n            - --tls-cert-file=/etc/kubernetes/ssl/apiserver.pem\n            - --tls-private-key-file=/etc/kubernetes/ssl/apiserver-key.pem\n            - --client-ca-file=/etc/kubernetes/ssl/ca.pem\n            - --service-account-key-file=/etc/kubernetes/ssl/apiserver-key.pem\n            - --anonymous-auth=false\n            livenessProbe:\n              httpGet:\n                host: 127.0.0.1\n                port: 8080\n                path: /healthz\n              initialDelaySeconds: 15\n              timeoutSeconds: 15\n            ports:\n            - containerPort: 443\n              hostPort: 443\n              name: https\n            - containerPort: 8080\n              hostPort: 8080\n              name: local\n            volumeMounts:\n            - mountPath: /etc/kubernetes/ssl\n              name: ssl-certs-kubernetes\n              readOnly: true\n            - mountPath: /etc/ssl/certs\n              name: ssl-certs-host\n              readOnly: true\n          volumes:\n          - hostPath:\n              path: /etc/kubernetes/ssl\n            name: ssl-certs-kubernetes\n          - hostPath:\n              path: /usr/share/ca-certificates\n            name: ssl-certs-host\n  - path: \"/etc/kubernetes/manifests/kube-proxy.yaml\"\n    permissions: \"0755\"\n    content: |\n        apiVersion: v1\n        kind: Pod\n        metadata:\n          name: kube-proxy\n          namespace: kube-system\n        spec:\n          hostNetwork: true\n          containers:\n          - name: kube-proxy\n            image: quay.io/coreos/hyperkube:v1.7.3_coreos.0\n            command:\n            - /hyperkube\n            - proxy\n            - --master=http://127.0.0.1:8080\n            - --proxy-mode=iptables\n            securityContext:\n              privileged: true\n            volumeMounts:\n            - mountPath: /etc/ssl/certs\n              name: ssl-certs-host\n              readOnly: true\n          volumes:\n          - hostPath:\n              path: /usr/share/ca-certificates\n            name: ssl-certs-host\n  - path: \"/etc/kubernetes/manifests/kube-controller-manager.yaml\"\n    permissions: \"0755\"\n    content: |\n        apiVersion: v1\n        kind: Pod\n        metadata:\n          name: kube-controller-manager\n          namespace: kube-system\n        spec:\n          hostNetwork: true\n          containers:\n          - name: kube-controller-manager\n            image: quay.io/coreos/hyperkube:v1.7.3_coreos.0\n            command:\n            - /hyperkube\n            - controller-manager\n            - --master=http://127.0.0.1:8080\n            - --leader-elect=true\n            - --service-account-private-key-file=/etc/kubernetes/ssl/apiserver-key.pem\n            - --root-ca-file=/etc/kubernetes/ssl/ca.pem\n            livenessProbe:\n              httpGet:\n                host: 127.0.0.1\n                path: /healthz\n                port: 10252\n              initialDelaySeconds: 15\n              timeoutSeconds: 1\n            volumeMounts:\n            - mountPath: /etc/kubernetes/ssl\n              name: ssl-certs-kubernetes\n              readOnly: true\n            - mountPath: /etc/ssl/certs\n              name: ssl-certs-host\n              readOnly: true\n          volumes:\n          - hostPath:\n              path: /etc/kubernetes/ssl\n            name: ssl-certs-kubernetes\n          - hostPath:\n              path: /usr/share/ca-certificates\n            name: ssl-certs-host\n  - path: \"/etc/kubernetes/manifests/kube-scheduler.yaml\"\n    permissions: \"0755\"\n    content: |\n        apiVersion: v1\n        kind: Pod\n        metadata:\n          name: kube-scheduler\n          namespace: kube-system\n        spec:\n          hostNetwork: true\n          containers:\n          - name: kube-scheduler\n            image: quay.io/coreos/hyperkube:v1.7.3_coreos.0\n            command:\n            - /hyperkube\n            - scheduler\n            - --master=http://127.0.0.1:8080\n            - --leader-elect=true\n            livenessProbe:\n              httpGet:\n                host: 127.0.0.1\n                path: /healthz\n                port: 10251\n              initialDelaySeconds: 15\n              timeoutSeconds: 15\n",
                            "vcpus": "1"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": ""
                },
                "digitalocean_droplet.k8s_worker": {
                    "type": "digitalocean_droplet",
                    "depends_on": [
                        "data.template_file.worker_yaml"
                    ],
                    "primary": {
                        "id": "68973546",
                        "attributes": {
                            "disk": "20",
                            "id": "68973546",
                            "image": "coreos-stable",
                            "ipv4_address": "45.55.172.250",
                            "ipv4_address_private": "10.132.6.97",
                            "locked": "false",
                            "name": "k8s-worker-01",
                            "price_hourly": "0.00744",
                            "price_monthly": "5",
                            "private_networking": "true",
                            "region": "nyc3",
                            "resize_disk": "true",
                            "size": "512mb",
                            "ssh_keys.#": "1",
                            "ssh_keys.0": "b4:9a:a0:b0:e5:e1:39:5f:0b:5c:1e:10:6d:d9:77:5b",
                            "status": "active",
                            "tags.#": "0",
                            "user_data": "#cloud-config\n\n\nwrite_files:\n  - path: \"/etc/flannel/options.env\"\n    permissions: \"0755\"\n    content: |\n        FLANNELD_IFACE=$private_ipv4\n        FLANNELD_ETCD_ENDPOINTS=https://10.132.44.189:2379\n        FLANNELD_ETCD_CAFILE=/etc/ssl/etcd/ca.pem\n        FLANNELD_ETCD_CERTFILE=/etc/ssl/etcd/worker.pem\n        FLANNELD_ETCD_KEYFILE=/etc/ssl/etcd/worker-key.pem\n  - path: \"/etc/systemd/system/flanneld.service.d/40-ExecStartPre-symlink.conf\"\n    permissions: \"0755\"\n    content: |\n        [Service]\n        ExecStartPre=/usr/bin/ln -sf /etc/flannel/options.env /run/flannel/options.env\n  - path: \"/etc/systemd/system/docker.service.d/40-flannel.conf\"\n    permissions: \"0755\"\n    content: |\n        [Unit]\n        Requires=flanneld.service\n        After=flanneld.service\n  - path: \"/etc/systemd/system/kubelet.service\"\n    permissions: \"0755\"\n    content: |\n        [Service]\n        Environment=KUBELET_IMAGE_TAG=v1.7.3_coreos.0\n        Environment=\"RKT_RUN_ARGS=--uuid-file-save=/var/run/kubelet-pod.uuid \\\n          --volume dns,kind=host,source=/etc/resolv.conf \\\n          --mount volume=dns,target=/etc/resolv.conf \\\n          --volume var-log,kind=host,source=/var/log \\\n          --mount volume=var-log,target=/var/log\"\n        ExecStartPre=/usr/bin/mkdir -p /etc/kubernetes/manifests\n        ExecStartPre=/usr/bin/mkdir -p /var/log/containers\n        ExecStartPre=-/usr/bin/rkt rm --uuid-file=/var/run/kubelet-pod.uuid\n        ExecStart=/usr/lib/coreos/kubelet-wrapper \\\n          --anonymous-auth=false \\\n          --client-ca-file=/etc/kubernetes/ssl/ca.pem \\\n          --api-servers=https://10.132.69.8 \\\n          --network-plugin-dir=/etc/kubernetes/cni/net.d \\\n          --container-runtime=docker \\\n          --register-node=true \\\n          --allow-privileged=true \\\n          --pod-manifest-path=/etc/kubernetes/manifests \\\n          --hostname-override=$private_ipv4 \\\n          --cluster-dns=10.3.0.10 \\\n          --cluster-domain=cluster.local \\\n          --kubeconfig=/etc/kubernetes/worker-kubeconfig.yaml \\\n          --tls-cert-file=/etc/kubernetes/ssl/worker.pem \\\n          --tls-private-key-file=/etc/kubernetes/ssl/worker-key.pem \\\n          --node-labels=kubernetes.io/role=node\n        ExecStop=-/usr/bin/rkt stop --uuid-file=/var/run/kubelet-pod.uuid\n        Restart=always\n        RestartSec=10\n\n        [Install]\n        WantedBy=multi-user.target\n  - path: \"/etc/kubernetes/manifests/kube-proxy.yaml\"\n    permissions: \"0755\"\n    content: |\n        apiVersion: v1\n        kind: Pod\n        metadata:\n          name: kube-proxy\n          namespace: kube-system\n        spec:\n          hostNetwork: true\n          containers:\n          - name: kube-proxy\n            image: quay.io/coreos/hyperkube:v1.7.3_coreos.0\n            command:\n            - /hyperkube\n            - proxy\n            - --master=https://10.132.69.8\n            - --kubeconfig=/etc/kubernetes/worker-kubeconfig.yaml\n            - --proxy-mode=iptables\n            securityContext:\n              privileged: true\n            volumeMounts:\n              - mountPath: /etc/ssl/certs\n                name: \"ssl-certs\"\n              - mountPath: /etc/kubernetes/worker-kubeconfig.yaml\n                name: \"kubeconfig\"\n                readOnly: true\n              - mountPath: /etc/kubernetes/ssl\n                name: \"etc-kube-ssl\"\n                readOnly: true\n          volumes:\n            - name: \"ssl-certs\"\n              hostPath:\n                path: \"/usr/share/ca-certificates\"\n            - name: \"kubeconfig\"\n              hostPath:\n                path: \"/etc/kubernetes/worker-kubeconfig.yaml\"\n            - name: \"etc-kube-ssl\"\n              hostPath:\n                path: \"/etc/kubernetes/ssl\"\n  - path: \"/etc/kubernetes/worker-kubeconfig.yaml\"\n    permissions: \"0755\"\n    content: |\n        apiVersion: v1\n        kind: Config\n        clusters:\n        - name: local\n          cluster:\n            certificate-authority: /etc/kubernetes/ssl/ca.pem\n        users:\n        - name: kubelet\n          user:\n            client-certificate: /etc/kubernetes/ssl/worker.pem\n            client-key: /etc/kubernetes/ssl/worker-key.pem\n        contexts:\n        - context:\n            cluster: local\n            user: kubelet\n          name: kubelet-context\n        current-context: kubelet-context\n",
                            "vcpus": "1"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": ""
                },
                "null_resource.deploy_dns_addon": {
                    "type": "null_resource",
                    "depends_on": [
                        "null_resource.setup_kubectl"
                    ],
                    "primary": {
                        "id": "4664444272647771248",
                        "attributes": {
                            "id": "4664444272647771248"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": ""
                },
                "null_resource.deploy_microbot": {
                    "type": "null_resource",
                    "depends_on": [
                        "digitalocean_droplet.k8s_worker",
                        "null_resource.setup_kubectl"
                    ],
                    "primary": {
                        "id": "797557180299020439",
                        "attributes": {
                            "id": "797557180299020439"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": ""
                },
                "null_resource.make_admin_key": {
                    "type": "null_resource",
                    "depends_on": [
                        "digitalocean_droplet.k8s_worker"
                    ],
                    "primary": {
                        "id": "6541101287037061862",
                        "attributes": {
                            "id": "6541101287037061862"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": ""
                },
                "null_resource.setup_kubectl": {
                    "type": "null_resource",
                    "depends_on": [
                        "digitalocean_droplet.k8s_master",
                        "null_resource.make_admin_key"
                    ],
                    "primary": {
                        "id": "5519472486041203646",
                        "attributes": {
                            "id": "5519472486041203646"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": ""
                }
            },
            "depends_on": []
        }
    ]
}
